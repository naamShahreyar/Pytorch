{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2        3  4\n",
       "0  3.62160  8.6661 -2.8073 -0.44699  0\n",
       "1  4.54590  8.1674 -2.4586 -1.46210  0\n",
       "2  3.86600 -2.6383  1.9242  0.10645  0\n",
       "3  3.45660  9.5228 -4.0112 -3.59440  0\n",
       "4  0.32924 -4.4552  4.5718 -0.98880  0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('/home/cloudcraftz/HandsOnPytorch/Data/data_banknote_authentication.txt', header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[[0,1,2,3]].values\n",
    "Y = data[4].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self,X,y):\n",
    "        self.features = torch.tensor(X, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(y, dtype = torch.float32)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.features[index]\n",
    "        y = self.labels[index]\n",
    "\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1097"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(X.shape[0]*0.80)\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_size = X.shape[0] - train_size\n",
    "val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(X,Y)\n",
    "\n",
    "torch.manual_seed(1)\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=10,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_set,\n",
    "    batch_size=10,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(in_features=num_features, out_features=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        logits = self.linear(x)\n",
    "        probas = torch.sigmoid(logits)\n",
    "        return probas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/200 | Batch 000/110 | Loss: 1.30\n",
      "Epoch: 001/200 | Batch 020/110 | Loss: 0.85\n",
      "Epoch: 001/200 | Batch 040/110 | Loss: 0.66\n",
      "Epoch: 001/200 | Batch 060/110 | Loss: 0.37\n",
      "Epoch: 001/200 | Batch 080/110 | Loss: 0.28\n",
      "Epoch: 001/200 | Batch 100/110 | Loss: 0.29\n",
      "Epoch: 002/200 | Batch 000/110 | Loss: 0.39\n",
      "Epoch: 002/200 | Batch 020/110 | Loss: 0.22\n",
      "Epoch: 002/200 | Batch 040/110 | Loss: 0.35\n",
      "Epoch: 002/200 | Batch 060/110 | Loss: 0.19\n",
      "Epoch: 002/200 | Batch 080/110 | Loss: 0.19\n",
      "Epoch: 002/200 | Batch 100/110 | Loss: 0.18\n",
      "Epoch: 003/200 | Batch 000/110 | Loss: 0.13\n",
      "Epoch: 003/200 | Batch 020/110 | Loss: 0.28\n",
      "Epoch: 003/200 | Batch 040/110 | Loss: 0.21\n",
      "Epoch: 003/200 | Batch 060/110 | Loss: 0.37\n",
      "Epoch: 003/200 | Batch 080/110 | Loss: 0.18\n",
      "Epoch: 003/200 | Batch 100/110 | Loss: 0.14\n",
      "Epoch: 004/200 | Batch 000/110 | Loss: 0.15\n",
      "Epoch: 004/200 | Batch 020/110 | Loss: 0.07\n",
      "Epoch: 004/200 | Batch 040/110 | Loss: 0.17\n",
      "Epoch: 004/200 | Batch 060/110 | Loss: 0.16\n",
      "Epoch: 004/200 | Batch 080/110 | Loss: 0.05\n",
      "Epoch: 004/200 | Batch 100/110 | Loss: 0.12\n",
      "Epoch: 005/200 | Batch 000/110 | Loss: 0.33\n",
      "Epoch: 005/200 | Batch 020/110 | Loss: 0.14\n",
      "Epoch: 005/200 | Batch 040/110 | Loss: 0.12\n",
      "Epoch: 005/200 | Batch 060/110 | Loss: 0.22\n",
      "Epoch: 005/200 | Batch 080/110 | Loss: 0.20\n",
      "Epoch: 005/200 | Batch 100/110 | Loss: 0.23\n",
      "Epoch: 006/200 | Batch 000/110 | Loss: 0.18\n",
      "Epoch: 006/200 | Batch 020/110 | Loss: 0.17\n",
      "Epoch: 006/200 | Batch 040/110 | Loss: 0.28\n",
      "Epoch: 006/200 | Batch 060/110 | Loss: 0.17\n",
      "Epoch: 006/200 | Batch 080/110 | Loss: 0.09\n",
      "Epoch: 006/200 | Batch 100/110 | Loss: 0.16\n",
      "Epoch: 007/200 | Batch 000/110 | Loss: 0.08\n",
      "Epoch: 007/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 007/200 | Batch 040/110 | Loss: 0.13\n",
      "Epoch: 007/200 | Batch 060/110 | Loss: 0.04\n",
      "Epoch: 007/200 | Batch 080/110 | Loss: 0.19\n",
      "Epoch: 007/200 | Batch 100/110 | Loss: 0.10\n",
      "Epoch: 008/200 | Batch 000/110 | Loss: 0.10\n",
      "Epoch: 008/200 | Batch 020/110 | Loss: 0.09\n",
      "Epoch: 008/200 | Batch 040/110 | Loss: 0.06\n",
      "Epoch: 008/200 | Batch 060/110 | Loss: 0.20\n",
      "Epoch: 008/200 | Batch 080/110 | Loss: 0.07\n",
      "Epoch: 008/200 | Batch 100/110 | Loss: 0.24\n",
      "Epoch: 009/200 | Batch 000/110 | Loss: 0.10\n",
      "Epoch: 009/200 | Batch 020/110 | Loss: 0.10\n",
      "Epoch: 009/200 | Batch 040/110 | Loss: 0.05\n",
      "Epoch: 009/200 | Batch 060/110 | Loss: 0.12\n",
      "Epoch: 009/200 | Batch 080/110 | Loss: 0.08\n",
      "Epoch: 009/200 | Batch 100/110 | Loss: 0.06\n",
      "Epoch: 010/200 | Batch 000/110 | Loss: 0.14\n",
      "Epoch: 010/200 | Batch 020/110 | Loss: 0.07\n",
      "Epoch: 010/200 | Batch 040/110 | Loss: 0.09\n",
      "Epoch: 010/200 | Batch 060/110 | Loss: 0.12\n",
      "Epoch: 010/200 | Batch 080/110 | Loss: 0.10\n",
      "Epoch: 010/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 011/200 | Batch 000/110 | Loss: 0.05\n",
      "Epoch: 011/200 | Batch 020/110 | Loss: 0.03\n",
      "Epoch: 011/200 | Batch 040/110 | Loss: 0.27\n",
      "Epoch: 011/200 | Batch 060/110 | Loss: 0.12\n",
      "Epoch: 011/200 | Batch 080/110 | Loss: 0.22\n",
      "Epoch: 011/200 | Batch 100/110 | Loss: 0.03\n",
      "Epoch: 012/200 | Batch 000/110 | Loss: 0.09\n",
      "Epoch: 012/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 012/200 | Batch 040/110 | Loss: 0.10\n",
      "Epoch: 012/200 | Batch 060/110 | Loss: 0.08\n",
      "Epoch: 012/200 | Batch 080/110 | Loss: 0.09\n",
      "Epoch: 012/200 | Batch 100/110 | Loss: 0.04\n",
      "Epoch: 013/200 | Batch 000/110 | Loss: 0.05\n",
      "Epoch: 013/200 | Batch 020/110 | Loss: 0.06\n",
      "Epoch: 013/200 | Batch 040/110 | Loss: 0.09\n",
      "Epoch: 013/200 | Batch 060/110 | Loss: 0.05\n",
      "Epoch: 013/200 | Batch 080/110 | Loss: 0.14\n",
      "Epoch: 013/200 | Batch 100/110 | Loss: 0.24\n",
      "Epoch: 014/200 | Batch 000/110 | Loss: 0.15\n",
      "Epoch: 014/200 | Batch 020/110 | Loss: 0.06\n",
      "Epoch: 014/200 | Batch 040/110 | Loss: 0.03\n",
      "Epoch: 014/200 | Batch 060/110 | Loss: 0.15\n",
      "Epoch: 014/200 | Batch 080/110 | Loss: 0.03\n",
      "Epoch: 014/200 | Batch 100/110 | Loss: 0.15\n",
      "Epoch: 015/200 | Batch 000/110 | Loss: 0.18\n",
      "Epoch: 015/200 | Batch 020/110 | Loss: 0.03\n",
      "Epoch: 015/200 | Batch 040/110 | Loss: 0.04\n",
      "Epoch: 015/200 | Batch 060/110 | Loss: 0.02\n",
      "Epoch: 015/200 | Batch 080/110 | Loss: 0.05\n",
      "Epoch: 015/200 | Batch 100/110 | Loss: 0.20\n",
      "Epoch: 016/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 016/200 | Batch 020/110 | Loss: 0.05\n",
      "Epoch: 016/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 016/200 | Batch 060/110 | Loss: 0.07\n",
      "Epoch: 016/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 016/200 | Batch 100/110 | Loss: 0.05\n",
      "Epoch: 017/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 017/200 | Batch 020/110 | Loss: 0.17\n",
      "Epoch: 017/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 017/200 | Batch 060/110 | Loss: 0.14\n",
      "Epoch: 017/200 | Batch 080/110 | Loss: 0.09\n",
      "Epoch: 017/200 | Batch 100/110 | Loss: 0.11\n",
      "Epoch: 018/200 | Batch 000/110 | Loss: 0.11\n",
      "Epoch: 018/200 | Batch 020/110 | Loss: 0.03\n",
      "Epoch: 018/200 | Batch 040/110 | Loss: 0.09\n",
      "Epoch: 018/200 | Batch 060/110 | Loss: 0.10\n",
      "Epoch: 018/200 | Batch 080/110 | Loss: 0.10\n",
      "Epoch: 018/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 019/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 019/200 | Batch 020/110 | Loss: 0.09\n",
      "Epoch: 019/200 | Batch 040/110 | Loss: 0.03\n",
      "Epoch: 019/200 | Batch 060/110 | Loss: 0.02\n",
      "Epoch: 019/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 019/200 | Batch 100/110 | Loss: 0.08\n",
      "Epoch: 020/200 | Batch 000/110 | Loss: 0.13\n",
      "Epoch: 020/200 | Batch 020/110 | Loss: 0.11\n",
      "Epoch: 020/200 | Batch 040/110 | Loss: 0.08\n",
      "Epoch: 020/200 | Batch 060/110 | Loss: 0.05\n",
      "Epoch: 020/200 | Batch 080/110 | Loss: 0.05\n",
      "Epoch: 020/200 | Batch 100/110 | Loss: 0.03\n",
      "Epoch: 021/200 | Batch 000/110 | Loss: 0.13\n",
      "Epoch: 021/200 | Batch 020/110 | Loss: 0.05\n",
      "Epoch: 021/200 | Batch 040/110 | Loss: 0.16\n",
      "Epoch: 021/200 | Batch 060/110 | Loss: 0.06\n",
      "Epoch: 021/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 021/200 | Batch 100/110 | Loss: 0.09\n",
      "Epoch: 022/200 | Batch 000/110 | Loss: 0.06\n",
      "Epoch: 022/200 | Batch 020/110 | Loss: 0.10\n",
      "Epoch: 022/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 022/200 | Batch 060/110 | Loss: 0.08\n",
      "Epoch: 022/200 | Batch 080/110 | Loss: 0.17\n",
      "Epoch: 022/200 | Batch 100/110 | Loss: 0.02\n",
      "Epoch: 023/200 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 023/200 | Batch 020/110 | Loss: 0.17\n",
      "Epoch: 023/200 | Batch 040/110 | Loss: 0.05\n",
      "Epoch: 023/200 | Batch 060/110 | Loss: 0.04\n",
      "Epoch: 023/200 | Batch 080/110 | Loss: 0.04\n",
      "Epoch: 023/200 | Batch 100/110 | Loss: 0.08\n",
      "Epoch: 024/200 | Batch 000/110 | Loss: 0.10\n",
      "Epoch: 024/200 | Batch 020/110 | Loss: 0.22\n",
      "Epoch: 024/200 | Batch 040/110 | Loss: 0.02\n",
      "Epoch: 024/200 | Batch 060/110 | Loss: 0.02\n",
      "Epoch: 024/200 | Batch 080/110 | Loss: 0.13\n",
      "Epoch: 024/200 | Batch 100/110 | Loss: 0.05\n",
      "Epoch: 025/200 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 025/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 025/200 | Batch 040/110 | Loss: 0.10\n",
      "Epoch: 025/200 | Batch 060/110 | Loss: 0.06\n",
      "Epoch: 025/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 025/200 | Batch 100/110 | Loss: 0.03\n",
      "Epoch: 026/200 | Batch 000/110 | Loss: 0.13\n",
      "Epoch: 026/200 | Batch 020/110 | Loss: 0.05\n",
      "Epoch: 026/200 | Batch 040/110 | Loss: 0.09\n",
      "Epoch: 026/200 | Batch 060/110 | Loss: 0.16\n",
      "Epoch: 026/200 | Batch 080/110 | Loss: 0.19\n",
      "Epoch: 026/200 | Batch 100/110 | Loss: 0.06\n",
      "Epoch: 027/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 027/200 | Batch 020/110 | Loss: 0.05\n",
      "Epoch: 027/200 | Batch 040/110 | Loss: 0.03\n",
      "Epoch: 027/200 | Batch 060/110 | Loss: 0.08\n",
      "Epoch: 027/200 | Batch 080/110 | Loss: 0.03\n",
      "Epoch: 027/200 | Batch 100/110 | Loss: 0.00\n",
      "Epoch: 028/200 | Batch 000/110 | Loss: 0.14\n",
      "Epoch: 028/200 | Batch 020/110 | Loss: 0.05\n",
      "Epoch: 028/200 | Batch 040/110 | Loss: 0.07\n",
      "Epoch: 028/200 | Batch 060/110 | Loss: 0.05\n",
      "Epoch: 028/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 028/200 | Batch 100/110 | Loss: 0.19\n",
      "Epoch: 029/200 | Batch 000/110 | Loss: 0.19\n",
      "Epoch: 029/200 | Batch 020/110 | Loss: 0.04\n",
      "Epoch: 029/200 | Batch 040/110 | Loss: 0.11\n",
      "Epoch: 029/200 | Batch 060/110 | Loss: 0.05\n",
      "Epoch: 029/200 | Batch 080/110 | Loss: 0.10\n",
      "Epoch: 029/200 | Batch 100/110 | Loss: 0.02\n",
      "Epoch: 030/200 | Batch 000/110 | Loss: 0.15\n",
      "Epoch: 030/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 030/200 | Batch 040/110 | Loss: 0.08\n",
      "Epoch: 030/200 | Batch 060/110 | Loss: 0.13\n",
      "Epoch: 030/200 | Batch 080/110 | Loss: 0.04\n",
      "Epoch: 030/200 | Batch 100/110 | Loss: 0.03\n",
      "Epoch: 031/200 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 031/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 031/200 | Batch 040/110 | Loss: 0.12\n",
      "Epoch: 031/200 | Batch 060/110 | Loss: 0.05\n",
      "Epoch: 031/200 | Batch 080/110 | Loss: 0.09\n",
      "Epoch: 031/200 | Batch 100/110 | Loss: 0.10\n",
      "Epoch: 032/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 032/200 | Batch 020/110 | Loss: 0.03\n",
      "Epoch: 032/200 | Batch 040/110 | Loss: 0.17\n",
      "Epoch: 032/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 032/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 032/200 | Batch 100/110 | Loss: 0.08\n",
      "Epoch: 033/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 033/200 | Batch 020/110 | Loss: 0.13\n",
      "Epoch: 033/200 | Batch 040/110 | Loss: 0.17\n",
      "Epoch: 033/200 | Batch 060/110 | Loss: 0.03\n",
      "Epoch: 033/200 | Batch 080/110 | Loss: 0.03\n",
      "Epoch: 033/200 | Batch 100/110 | Loss: 0.05\n",
      "Epoch: 034/200 | Batch 000/110 | Loss: 0.06\n",
      "Epoch: 034/200 | Batch 020/110 | Loss: 0.08\n",
      "Epoch: 034/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 034/200 | Batch 060/110 | Loss: 0.06\n",
      "Epoch: 034/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 034/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 035/200 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 035/200 | Batch 020/110 | Loss: 0.05\n",
      "Epoch: 035/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 035/200 | Batch 060/110 | Loss: 0.04\n",
      "Epoch: 035/200 | Batch 080/110 | Loss: 0.07\n",
      "Epoch: 035/200 | Batch 100/110 | Loss: 0.05\n",
      "Epoch: 036/200 | Batch 000/110 | Loss: 0.07\n",
      "Epoch: 036/200 | Batch 020/110 | Loss: 0.03\n",
      "Epoch: 036/200 | Batch 040/110 | Loss: 0.03\n",
      "Epoch: 036/200 | Batch 060/110 | Loss: 0.02\n",
      "Epoch: 036/200 | Batch 080/110 | Loss: 0.18\n",
      "Epoch: 036/200 | Batch 100/110 | Loss: 0.10\n",
      "Epoch: 037/200 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 037/200 | Batch 020/110 | Loss: 0.03\n",
      "Epoch: 037/200 | Batch 040/110 | Loss: 0.03\n",
      "Epoch: 037/200 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 037/200 | Batch 080/110 | Loss: 0.00\n",
      "Epoch: 037/200 | Batch 100/110 | Loss: 0.18\n",
      "Epoch: 038/200 | Batch 000/110 | Loss: 0.05\n",
      "Epoch: 038/200 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 038/200 | Batch 040/110 | Loss: 0.03\n",
      "Epoch: 038/200 | Batch 060/110 | Loss: 0.02\n",
      "Epoch: 038/200 | Batch 080/110 | Loss: 0.06\n",
      "Epoch: 038/200 | Batch 100/110 | Loss: 0.10\n",
      "Epoch: 039/200 | Batch 000/110 | Loss: 0.19\n",
      "Epoch: 039/200 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 039/200 | Batch 040/110 | Loss: 0.16\n",
      "Epoch: 039/200 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 039/200 | Batch 080/110 | Loss: 0.04\n",
      "Epoch: 039/200 | Batch 100/110 | Loss: 0.10\n",
      "Epoch: 040/200 | Batch 000/110 | Loss: 0.15\n",
      "Epoch: 040/200 | Batch 020/110 | Loss: 0.05\n",
      "Epoch: 040/200 | Batch 040/110 | Loss: 0.07\n",
      "Epoch: 040/200 | Batch 060/110 | Loss: 0.05\n",
      "Epoch: 040/200 | Batch 080/110 | Loss: 0.06\n",
      "Epoch: 040/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 041/200 | Batch 000/110 | Loss: 0.05\n",
      "Epoch: 041/200 | Batch 020/110 | Loss: 0.07\n",
      "Epoch: 041/200 | Batch 040/110 | Loss: 0.11\n",
      "Epoch: 041/200 | Batch 060/110 | Loss: 0.12\n",
      "Epoch: 041/200 | Batch 080/110 | Loss: 0.17\n",
      "Epoch: 041/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 042/200 | Batch 000/110 | Loss: 0.15\n",
      "Epoch: 042/200 | Batch 020/110 | Loss: 0.04\n",
      "Epoch: 042/200 | Batch 040/110 | Loss: 0.02\n",
      "Epoch: 042/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 042/200 | Batch 080/110 | Loss: 0.21\n",
      "Epoch: 042/200 | Batch 100/110 | Loss: 0.06\n",
      "Epoch: 043/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 043/200 | Batch 020/110 | Loss: 0.05\n",
      "Epoch: 043/200 | Batch 040/110 | Loss: 0.15\n",
      "Epoch: 043/200 | Batch 060/110 | Loss: 0.02\n",
      "Epoch: 043/200 | Batch 080/110 | Loss: 0.08\n",
      "Epoch: 043/200 | Batch 100/110 | Loss: 0.02\n",
      "Epoch: 044/200 | Batch 000/110 | Loss: 0.05\n",
      "Epoch: 044/200 | Batch 020/110 | Loss: 0.07\n",
      "Epoch: 044/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 044/200 | Batch 060/110 | Loss: 0.09\n",
      "Epoch: 044/200 | Batch 080/110 | Loss: 0.04\n",
      "Epoch: 044/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 045/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 045/200 | Batch 020/110 | Loss: 0.15\n",
      "Epoch: 045/200 | Batch 040/110 | Loss: 0.13\n",
      "Epoch: 045/200 | Batch 060/110 | Loss: 0.03\n",
      "Epoch: 045/200 | Batch 080/110 | Loss: 0.09\n",
      "Epoch: 045/200 | Batch 100/110 | Loss: 0.10\n",
      "Epoch: 046/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 046/200 | Batch 020/110 | Loss: 0.03\n",
      "Epoch: 046/200 | Batch 040/110 | Loss: 0.04\n",
      "Epoch: 046/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 046/200 | Batch 080/110 | Loss: 0.04\n",
      "Epoch: 046/200 | Batch 100/110 | Loss: 0.02\n",
      "Epoch: 047/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 047/200 | Batch 020/110 | Loss: 0.05\n",
      "Epoch: 047/200 | Batch 040/110 | Loss: 0.20\n",
      "Epoch: 047/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 047/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 047/200 | Batch 100/110 | Loss: 0.07\n",
      "Epoch: 048/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 048/200 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 048/200 | Batch 040/110 | Loss: 0.19\n",
      "Epoch: 048/200 | Batch 060/110 | Loss: 0.02\n",
      "Epoch: 048/200 | Batch 080/110 | Loss: 0.03\n",
      "Epoch: 048/200 | Batch 100/110 | Loss: 0.05\n",
      "Epoch: 049/200 | Batch 000/110 | Loss: 0.04\n",
      "Epoch: 049/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 049/200 | Batch 040/110 | Loss: 0.17\n",
      "Epoch: 049/200 | Batch 060/110 | Loss: 0.08\n",
      "Epoch: 049/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 049/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 050/200 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 050/200 | Batch 020/110 | Loss: 0.09\n",
      "Epoch: 050/200 | Batch 040/110 | Loss: 0.05\n",
      "Epoch: 050/200 | Batch 060/110 | Loss: 0.02\n",
      "Epoch: 050/200 | Batch 080/110 | Loss: 0.03\n",
      "Epoch: 050/200 | Batch 100/110 | Loss: 0.03\n",
      "Epoch: 051/200 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 051/200 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 051/200 | Batch 040/110 | Loss: 0.04\n",
      "Epoch: 051/200 | Batch 060/110 | Loss: 0.02\n",
      "Epoch: 051/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 051/200 | Batch 100/110 | Loss: 0.09\n",
      "Epoch: 052/200 | Batch 000/110 | Loss: 0.13\n",
      "Epoch: 052/200 | Batch 020/110 | Loss: 0.11\n",
      "Epoch: 052/200 | Batch 040/110 | Loss: 0.02\n",
      "Epoch: 052/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 052/200 | Batch 080/110 | Loss: 0.17\n",
      "Epoch: 052/200 | Batch 100/110 | Loss: 0.07\n",
      "Epoch: 053/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 053/200 | Batch 020/110 | Loss: 0.11\n",
      "Epoch: 053/200 | Batch 040/110 | Loss: 0.06\n",
      "Epoch: 053/200 | Batch 060/110 | Loss: 0.05\n",
      "Epoch: 053/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 053/200 | Batch 100/110 | Loss: 0.05\n",
      "Epoch: 054/200 | Batch 000/110 | Loss: 0.04\n",
      "Epoch: 054/200 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 054/200 | Batch 040/110 | Loss: 0.04\n",
      "Epoch: 054/200 | Batch 060/110 | Loss: 0.07\n",
      "Epoch: 054/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 054/200 | Batch 100/110 | Loss: 0.05\n",
      "Epoch: 055/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 055/200 | Batch 020/110 | Loss: 0.04\n",
      "Epoch: 055/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 055/200 | Batch 060/110 | Loss: 0.03\n",
      "Epoch: 055/200 | Batch 080/110 | Loss: 0.05\n",
      "Epoch: 055/200 | Batch 100/110 | Loss: 0.12\n",
      "Epoch: 056/200 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 056/200 | Batch 020/110 | Loss: 0.10\n",
      "Epoch: 056/200 | Batch 040/110 | Loss: 0.10\n",
      "Epoch: 056/200 | Batch 060/110 | Loss: 0.04\n",
      "Epoch: 056/200 | Batch 080/110 | Loss: 0.00\n",
      "Epoch: 056/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 057/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 057/200 | Batch 020/110 | Loss: 0.03\n",
      "Epoch: 057/200 | Batch 040/110 | Loss: 0.22\n",
      "Epoch: 057/200 | Batch 060/110 | Loss: 0.13\n",
      "Epoch: 057/200 | Batch 080/110 | Loss: 0.06\n",
      "Epoch: 057/200 | Batch 100/110 | Loss: 0.02\n",
      "Epoch: 058/200 | Batch 000/110 | Loss: 0.07\n",
      "Epoch: 058/200 | Batch 020/110 | Loss: 0.04\n",
      "Epoch: 058/200 | Batch 040/110 | Loss: 0.02\n",
      "Epoch: 058/200 | Batch 060/110 | Loss: 0.05\n",
      "Epoch: 058/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 058/200 | Batch 100/110 | Loss: 0.03\n",
      "Epoch: 059/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 059/200 | Batch 020/110 | Loss: 0.04\n",
      "Epoch: 059/200 | Batch 040/110 | Loss: 0.06\n",
      "Epoch: 059/200 | Batch 060/110 | Loss: 0.05\n",
      "Epoch: 059/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 059/200 | Batch 100/110 | Loss: 0.06\n",
      "Epoch: 060/200 | Batch 000/110 | Loss: 0.04\n",
      "Epoch: 060/200 | Batch 020/110 | Loss: 0.21\n",
      "Epoch: 060/200 | Batch 040/110 | Loss: 0.10\n",
      "Epoch: 060/200 | Batch 060/110 | Loss: 0.10\n",
      "Epoch: 060/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 060/200 | Batch 100/110 | Loss: 0.03\n",
      "Epoch: 061/200 | Batch 000/110 | Loss: 0.04\n",
      "Epoch: 061/200 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 061/200 | Batch 040/110 | Loss: 0.07\n",
      "Epoch: 061/200 | Batch 060/110 | Loss: 0.07\n",
      "Epoch: 061/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 061/200 | Batch 100/110 | Loss: 0.04\n",
      "Epoch: 062/200 | Batch 000/110 | Loss: 0.05\n",
      "Epoch: 062/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 062/200 | Batch 040/110 | Loss: 0.12\n",
      "Epoch: 062/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 062/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 062/200 | Batch 100/110 | Loss: 0.15\n",
      "Epoch: 063/200 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 063/200 | Batch 020/110 | Loss: 0.03\n",
      "Epoch: 063/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 063/200 | Batch 060/110 | Loss: 0.19\n",
      "Epoch: 063/200 | Batch 080/110 | Loss: 0.06\n",
      "Epoch: 063/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 064/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 064/200 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 064/200 | Batch 040/110 | Loss: 0.03\n",
      "Epoch: 064/200 | Batch 060/110 | Loss: 0.05\n",
      "Epoch: 064/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 064/200 | Batch 100/110 | Loss: 0.16\n",
      "Epoch: 065/200 | Batch 000/110 | Loss: 0.08\n",
      "Epoch: 065/200 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 065/200 | Batch 040/110 | Loss: 0.02\n",
      "Epoch: 065/200 | Batch 060/110 | Loss: 0.04\n",
      "Epoch: 065/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 065/200 | Batch 100/110 | Loss: 0.05\n",
      "Epoch: 066/200 | Batch 000/110 | Loss: 0.12\n",
      "Epoch: 066/200 | Batch 020/110 | Loss: 0.04\n",
      "Epoch: 066/200 | Batch 040/110 | Loss: 0.10\n",
      "Epoch: 066/200 | Batch 060/110 | Loss: 0.03\n",
      "Epoch: 066/200 | Batch 080/110 | Loss: 0.04\n",
      "Epoch: 066/200 | Batch 100/110 | Loss: 0.04\n",
      "Epoch: 067/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 067/200 | Batch 020/110 | Loss: 0.03\n",
      "Epoch: 067/200 | Batch 040/110 | Loss: 0.02\n",
      "Epoch: 067/200 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 067/200 | Batch 080/110 | Loss: 0.12\n",
      "Epoch: 067/200 | Batch 100/110 | Loss: 0.04\n",
      "Epoch: 068/200 | Batch 000/110 | Loss: 0.17\n",
      "Epoch: 068/200 | Batch 020/110 | Loss: 0.12\n",
      "Epoch: 068/200 | Batch 040/110 | Loss: 0.22\n",
      "Epoch: 068/200 | Batch 060/110 | Loss: 0.07\n",
      "Epoch: 068/200 | Batch 080/110 | Loss: 0.04\n",
      "Epoch: 068/200 | Batch 100/110 | Loss: 0.02\n",
      "Epoch: 069/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 069/200 | Batch 020/110 | Loss: 0.03\n",
      "Epoch: 069/200 | Batch 040/110 | Loss: 0.03\n",
      "Epoch: 069/200 | Batch 060/110 | Loss: 0.06\n",
      "Epoch: 069/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 069/200 | Batch 100/110 | Loss: 0.03\n",
      "Epoch: 070/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 070/200 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 070/200 | Batch 040/110 | Loss: 0.03\n",
      "Epoch: 070/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 070/200 | Batch 080/110 | Loss: 0.06\n",
      "Epoch: 070/200 | Batch 100/110 | Loss: 0.14\n",
      "Epoch: 071/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 071/200 | Batch 020/110 | Loss: 0.03\n",
      "Epoch: 071/200 | Batch 040/110 | Loss: 0.06\n",
      "Epoch: 071/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 071/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 071/200 | Batch 100/110 | Loss: 0.02\n",
      "Epoch: 072/200 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 072/200 | Batch 020/110 | Loss: 0.03\n",
      "Epoch: 072/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 072/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 072/200 | Batch 080/110 | Loss: 0.11\n",
      "Epoch: 072/200 | Batch 100/110 | Loss: 0.02\n",
      "Epoch: 073/200 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 073/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 073/200 | Batch 040/110 | Loss: 0.17\n",
      "Epoch: 073/200 | Batch 060/110 | Loss: 0.03\n",
      "Epoch: 073/200 | Batch 080/110 | Loss: 0.16\n",
      "Epoch: 073/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 074/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 074/200 | Batch 020/110 | Loss: 0.08\n",
      "Epoch: 074/200 | Batch 040/110 | Loss: 0.05\n",
      "Epoch: 074/200 | Batch 060/110 | Loss: 0.04\n",
      "Epoch: 074/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 074/200 | Batch 100/110 | Loss: 0.02\n",
      "Epoch: 075/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 075/200 | Batch 020/110 | Loss: 0.04\n",
      "Epoch: 075/200 | Batch 040/110 | Loss: 0.04\n",
      "Epoch: 075/200 | Batch 060/110 | Loss: 0.03\n",
      "Epoch: 075/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 075/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 076/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 076/200 | Batch 020/110 | Loss: 0.05\n",
      "Epoch: 076/200 | Batch 040/110 | Loss: 0.04\n",
      "Epoch: 076/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 076/200 | Batch 080/110 | Loss: 0.14\n",
      "Epoch: 076/200 | Batch 100/110 | Loss: 0.07\n",
      "Epoch: 077/200 | Batch 000/110 | Loss: 0.11\n",
      "Epoch: 077/200 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 077/200 | Batch 040/110 | Loss: 0.16\n",
      "Epoch: 077/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 077/200 | Batch 080/110 | Loss: 0.00\n",
      "Epoch: 077/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 078/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 078/200 | Batch 020/110 | Loss: 0.08\n",
      "Epoch: 078/200 | Batch 040/110 | Loss: 0.13\n",
      "Epoch: 078/200 | Batch 060/110 | Loss: 0.15\n",
      "Epoch: 078/200 | Batch 080/110 | Loss: 0.15\n",
      "Epoch: 078/200 | Batch 100/110 | Loss: 0.00\n",
      "Epoch: 079/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 079/200 | Batch 020/110 | Loss: 0.12\n",
      "Epoch: 079/200 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 079/200 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 079/200 | Batch 080/110 | Loss: 0.11\n",
      "Epoch: 079/200 | Batch 100/110 | Loss: 0.00\n",
      "Epoch: 080/200 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 080/200 | Batch 020/110 | Loss: 0.08\n",
      "Epoch: 080/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 080/200 | Batch 060/110 | Loss: 0.06\n",
      "Epoch: 080/200 | Batch 080/110 | Loss: 0.06\n",
      "Epoch: 080/200 | Batch 100/110 | Loss: 0.02\n",
      "Epoch: 081/200 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 081/200 | Batch 020/110 | Loss: 0.07\n",
      "Epoch: 081/200 | Batch 040/110 | Loss: 0.10\n",
      "Epoch: 081/200 | Batch 060/110 | Loss: 0.02\n",
      "Epoch: 081/200 | Batch 080/110 | Loss: 0.03\n",
      "Epoch: 081/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 082/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 082/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 082/200 | Batch 040/110 | Loss: 0.02\n",
      "Epoch: 082/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 082/200 | Batch 080/110 | Loss: 0.15\n",
      "Epoch: 082/200 | Batch 100/110 | Loss: 0.03\n",
      "Epoch: 083/200 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 083/200 | Batch 020/110 | Loss: 0.05\n",
      "Epoch: 083/200 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 083/200 | Batch 060/110 | Loss: 0.03\n",
      "Epoch: 083/200 | Batch 080/110 | Loss: 0.08\n",
      "Epoch: 083/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 084/200 | Batch 000/110 | Loss: 0.11\n",
      "Epoch: 084/200 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 084/200 | Batch 040/110 | Loss: 0.02\n",
      "Epoch: 084/200 | Batch 060/110 | Loss: 0.12\n",
      "Epoch: 084/200 | Batch 080/110 | Loss: 0.04\n",
      "Epoch: 084/200 | Batch 100/110 | Loss: 0.11\n",
      "Epoch: 085/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 085/200 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 085/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 085/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 085/200 | Batch 080/110 | Loss: 0.12\n",
      "Epoch: 085/200 | Batch 100/110 | Loss: 0.03\n",
      "Epoch: 086/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 086/200 | Batch 020/110 | Loss: 0.06\n",
      "Epoch: 086/200 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 086/200 | Batch 060/110 | Loss: 0.03\n",
      "Epoch: 086/200 | Batch 080/110 | Loss: 0.00\n",
      "Epoch: 086/200 | Batch 100/110 | Loss: 0.06\n",
      "Epoch: 087/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 087/200 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 087/200 | Batch 040/110 | Loss: 0.03\n",
      "Epoch: 087/200 | Batch 060/110 | Loss: 0.04\n",
      "Epoch: 087/200 | Batch 080/110 | Loss: 0.03\n",
      "Epoch: 087/200 | Batch 100/110 | Loss: 0.06\n",
      "Epoch: 088/200 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 088/200 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 088/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 088/200 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 088/200 | Batch 080/110 | Loss: 0.03\n",
      "Epoch: 088/200 | Batch 100/110 | Loss: 0.06\n",
      "Epoch: 089/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 089/200 | Batch 020/110 | Loss: 0.08\n",
      "Epoch: 089/200 | Batch 040/110 | Loss: 0.02\n",
      "Epoch: 089/200 | Batch 060/110 | Loss: 0.10\n",
      "Epoch: 089/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 089/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 090/200 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 090/200 | Batch 020/110 | Loss: 0.05\n",
      "Epoch: 090/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 090/200 | Batch 060/110 | Loss: 0.17\n",
      "Epoch: 090/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 090/200 | Batch 100/110 | Loss: 0.03\n",
      "Epoch: 091/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 091/200 | Batch 020/110 | Loss: 0.04\n",
      "Epoch: 091/200 | Batch 040/110 | Loss: 0.02\n",
      "Epoch: 091/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 091/200 | Batch 080/110 | Loss: 0.05\n",
      "Epoch: 091/200 | Batch 100/110 | Loss: 0.18\n",
      "Epoch: 092/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 092/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 092/200 | Batch 040/110 | Loss: 0.07\n",
      "Epoch: 092/200 | Batch 060/110 | Loss: 0.02\n",
      "Epoch: 092/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 092/200 | Batch 100/110 | Loss: 0.03\n",
      "Epoch: 093/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 093/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 093/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 093/200 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 093/200 | Batch 080/110 | Loss: 0.00\n",
      "Epoch: 093/200 | Batch 100/110 | Loss: 0.05\n",
      "Epoch: 094/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 094/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 094/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 094/200 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 094/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 094/200 | Batch 100/110 | Loss: 0.00\n",
      "Epoch: 095/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 095/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 095/200 | Batch 040/110 | Loss: 0.03\n",
      "Epoch: 095/200 | Batch 060/110 | Loss: 0.03\n",
      "Epoch: 095/200 | Batch 080/110 | Loss: 0.12\n",
      "Epoch: 095/200 | Batch 100/110 | Loss: 0.04\n",
      "Epoch: 096/200 | Batch 000/110 | Loss: 0.04\n",
      "Epoch: 096/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 096/200 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 096/200 | Batch 060/110 | Loss: 0.03\n",
      "Epoch: 096/200 | Batch 080/110 | Loss: 0.04\n",
      "Epoch: 096/200 | Batch 100/110 | Loss: 0.00\n",
      "Epoch: 097/200 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 097/200 | Batch 020/110 | Loss: 0.10\n",
      "Epoch: 097/200 | Batch 040/110 | Loss: 0.02\n",
      "Epoch: 097/200 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 097/200 | Batch 080/110 | Loss: 0.08\n",
      "Epoch: 097/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 098/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 098/200 | Batch 020/110 | Loss: 0.05\n",
      "Epoch: 098/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 098/200 | Batch 060/110 | Loss: 0.08\n",
      "Epoch: 098/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 098/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 099/200 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 099/200 | Batch 020/110 | Loss: 0.06\n",
      "Epoch: 099/200 | Batch 040/110 | Loss: 0.21\n",
      "Epoch: 099/200 | Batch 060/110 | Loss: 0.04\n",
      "Epoch: 099/200 | Batch 080/110 | Loss: 0.03\n",
      "Epoch: 099/200 | Batch 100/110 | Loss: 0.13\n",
      "Epoch: 100/200 | Batch 000/110 | Loss: 0.05\n",
      "Epoch: 100/200 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 100/200 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 100/200 | Batch 060/110 | Loss: 0.24\n",
      "Epoch: 100/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 100/200 | Batch 100/110 | Loss: 0.04\n",
      "Epoch: 101/200 | Batch 000/110 | Loss: 0.04\n",
      "Epoch: 101/200 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 101/200 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 101/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 101/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 101/200 | Batch 100/110 | Loss: 0.04\n",
      "Epoch: 102/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 102/200 | Batch 020/110 | Loss: 0.07\n",
      "Epoch: 102/200 | Batch 040/110 | Loss: 0.03\n",
      "Epoch: 102/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 102/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 102/200 | Batch 100/110 | Loss: 0.02\n",
      "Epoch: 103/200 | Batch 000/110 | Loss: 0.13\n",
      "Epoch: 103/200 | Batch 020/110 | Loss: 0.04\n",
      "Epoch: 103/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 103/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 103/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 103/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 104/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 104/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 104/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 104/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 104/200 | Batch 080/110 | Loss: 0.05\n",
      "Epoch: 104/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 105/200 | Batch 000/110 | Loss: 0.04\n",
      "Epoch: 105/200 | Batch 020/110 | Loss: 0.03\n",
      "Epoch: 105/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 105/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 105/200 | Batch 080/110 | Loss: 0.13\n",
      "Epoch: 105/200 | Batch 100/110 | Loss: 0.03\n",
      "Epoch: 106/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 106/200 | Batch 020/110 | Loss: 0.06\n",
      "Epoch: 106/200 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 106/200 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 106/200 | Batch 080/110 | Loss: 0.03\n",
      "Epoch: 106/200 | Batch 100/110 | Loss: 0.06\n",
      "Epoch: 107/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 107/200 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 107/200 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 107/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 107/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 107/200 | Batch 100/110 | Loss: 0.00\n",
      "Epoch: 108/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 108/200 | Batch 020/110 | Loss: 0.04\n",
      "Epoch: 108/200 | Batch 040/110 | Loss: 0.03\n",
      "Epoch: 108/200 | Batch 060/110 | Loss: 0.06\n",
      "Epoch: 108/200 | Batch 080/110 | Loss: 0.00\n",
      "Epoch: 108/200 | Batch 100/110 | Loss: 0.00\n",
      "Epoch: 109/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 109/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 109/200 | Batch 040/110 | Loss: 0.02\n",
      "Epoch: 109/200 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 109/200 | Batch 080/110 | Loss: 0.05\n",
      "Epoch: 109/200 | Batch 100/110 | Loss: 0.02\n",
      "Epoch: 110/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 110/200 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 110/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 110/200 | Batch 060/110 | Loss: 0.02\n",
      "Epoch: 110/200 | Batch 080/110 | Loss: 0.03\n",
      "Epoch: 110/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 111/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 111/200 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 111/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 111/200 | Batch 060/110 | Loss: 0.03\n",
      "Epoch: 111/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 111/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 112/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 112/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 112/200 | Batch 040/110 | Loss: 0.08\n",
      "Epoch: 112/200 | Batch 060/110 | Loss: 0.04\n",
      "Epoch: 112/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 112/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 113/200 | Batch 000/110 | Loss: 0.14\n",
      "Epoch: 113/200 | Batch 020/110 | Loss: 0.12\n",
      "Epoch: 113/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 113/200 | Batch 060/110 | Loss: 0.02\n",
      "Epoch: 113/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 113/200 | Batch 100/110 | Loss: 0.04\n",
      "Epoch: 114/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 114/200 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 114/200 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 114/200 | Batch 060/110 | Loss: 0.08\n",
      "Epoch: 114/200 | Batch 080/110 | Loss: 0.03\n",
      "Epoch: 114/200 | Batch 100/110 | Loss: 0.00\n",
      "Epoch: 115/200 | Batch 000/110 | Loss: 0.11\n",
      "Epoch: 115/200 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 115/200 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 115/200 | Batch 060/110 | Loss: 0.02\n",
      "Epoch: 115/200 | Batch 080/110 | Loss: 0.13\n",
      "Epoch: 115/200 | Batch 100/110 | Loss: 0.02\n",
      "Epoch: 116/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 116/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 116/200 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 116/200 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 116/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 116/200 | Batch 100/110 | Loss: 0.02\n",
      "Epoch: 117/200 | Batch 000/110 | Loss: 0.06\n",
      "Epoch: 117/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 117/200 | Batch 040/110 | Loss: 0.03\n",
      "Epoch: 117/200 | Batch 060/110 | Loss: 0.02\n",
      "Epoch: 117/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 117/200 | Batch 100/110 | Loss: 0.02\n",
      "Epoch: 118/200 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 118/200 | Batch 020/110 | Loss: 0.05\n",
      "Epoch: 118/200 | Batch 040/110 | Loss: 0.03\n",
      "Epoch: 118/200 | Batch 060/110 | Loss: 0.04\n",
      "Epoch: 118/200 | Batch 080/110 | Loss: 0.00\n",
      "Epoch: 118/200 | Batch 100/110 | Loss: 0.04\n",
      "Epoch: 119/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 119/200 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 119/200 | Batch 040/110 | Loss: 0.04\n",
      "Epoch: 119/200 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 119/200 | Batch 080/110 | Loss: 0.07\n",
      "Epoch: 119/200 | Batch 100/110 | Loss: 0.04\n",
      "Epoch: 120/200 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 120/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 120/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 120/200 | Batch 060/110 | Loss: 0.03\n",
      "Epoch: 120/200 | Batch 080/110 | Loss: 0.03\n",
      "Epoch: 120/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 121/200 | Batch 000/110 | Loss: 0.06\n",
      "Epoch: 121/200 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 121/200 | Batch 040/110 | Loss: 0.11\n",
      "Epoch: 121/200 | Batch 060/110 | Loss: 0.12\n",
      "Epoch: 121/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 121/200 | Batch 100/110 | Loss: 0.00\n",
      "Epoch: 122/200 | Batch 000/110 | Loss: 0.04\n",
      "Epoch: 122/200 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 122/200 | Batch 040/110 | Loss: 0.02\n",
      "Epoch: 122/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 122/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 122/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 123/200 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 123/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 123/200 | Batch 040/110 | Loss: 0.04\n",
      "Epoch: 123/200 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 123/200 | Batch 080/110 | Loss: 0.04\n",
      "Epoch: 123/200 | Batch 100/110 | Loss: 0.11\n",
      "Epoch: 124/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 124/200 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 124/200 | Batch 040/110 | Loss: 0.10\n",
      "Epoch: 124/200 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 124/200 | Batch 080/110 | Loss: 0.00\n",
      "Epoch: 124/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 125/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 125/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 125/200 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 125/200 | Batch 060/110 | Loss: 0.03\n",
      "Epoch: 125/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 125/200 | Batch 100/110 | Loss: 0.10\n",
      "Epoch: 126/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 126/200 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 126/200 | Batch 040/110 | Loss: 0.02\n",
      "Epoch: 126/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 126/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 126/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 127/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 127/200 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 127/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 127/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 127/200 | Batch 080/110 | Loss: 0.14\n",
      "Epoch: 127/200 | Batch 100/110 | Loss: 0.10\n",
      "Epoch: 128/200 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 128/200 | Batch 020/110 | Loss: 0.30\n",
      "Epoch: 128/200 | Batch 040/110 | Loss: 0.03\n",
      "Epoch: 128/200 | Batch 060/110 | Loss: 0.18\n",
      "Epoch: 128/200 | Batch 080/110 | Loss: 0.05\n",
      "Epoch: 128/200 | Batch 100/110 | Loss: 0.09\n",
      "Epoch: 129/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 129/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 129/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 129/200 | Batch 060/110 | Loss: 0.05\n",
      "Epoch: 129/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 129/200 | Batch 100/110 | Loss: 0.00\n",
      "Epoch: 130/200 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 130/200 | Batch 020/110 | Loss: 0.10\n",
      "Epoch: 130/200 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 130/200 | Batch 060/110 | Loss: 0.02\n",
      "Epoch: 130/200 | Batch 080/110 | Loss: 0.05\n",
      "Epoch: 130/200 | Batch 100/110 | Loss: 0.00\n",
      "Epoch: 131/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 131/200 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 131/200 | Batch 040/110 | Loss: 0.03\n",
      "Epoch: 131/200 | Batch 060/110 | Loss: 0.03\n",
      "Epoch: 131/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 131/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 132/200 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 132/200 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 132/200 | Batch 040/110 | Loss: 0.05\n",
      "Epoch: 132/200 | Batch 060/110 | Loss: 0.04\n",
      "Epoch: 132/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 132/200 | Batch 100/110 | Loss: 0.02\n",
      "Epoch: 133/200 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 133/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 133/200 | Batch 040/110 | Loss: 0.21\n",
      "Epoch: 133/200 | Batch 060/110 | Loss: 0.07\n",
      "Epoch: 133/200 | Batch 080/110 | Loss: 0.00\n",
      "Epoch: 133/200 | Batch 100/110 | Loss: 0.02\n",
      "Epoch: 134/200 | Batch 000/110 | Loss: 0.13\n",
      "Epoch: 134/200 | Batch 020/110 | Loss: 0.03\n",
      "Epoch: 134/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 134/200 | Batch 060/110 | Loss: 0.03\n",
      "Epoch: 134/200 | Batch 080/110 | Loss: 0.00\n",
      "Epoch: 134/200 | Batch 100/110 | Loss: 0.07\n",
      "Epoch: 135/200 | Batch 000/110 | Loss: 0.09\n",
      "Epoch: 135/200 | Batch 020/110 | Loss: 0.04\n",
      "Epoch: 135/200 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 135/200 | Batch 060/110 | Loss: 0.03\n",
      "Epoch: 135/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 135/200 | Batch 100/110 | Loss: 0.06\n",
      "Epoch: 136/200 | Batch 000/110 | Loss: 0.10\n",
      "Epoch: 136/200 | Batch 020/110 | Loss: 0.09\n",
      "Epoch: 136/200 | Batch 040/110 | Loss: 0.13\n",
      "Epoch: 136/200 | Batch 060/110 | Loss: 0.03\n",
      "Epoch: 136/200 | Batch 080/110 | Loss: 0.04\n",
      "Epoch: 136/200 | Batch 100/110 | Loss: 0.02\n",
      "Epoch: 137/200 | Batch 000/110 | Loss: 0.10\n",
      "Epoch: 137/200 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 137/200 | Batch 040/110 | Loss: 0.04\n",
      "Epoch: 137/200 | Batch 060/110 | Loss: 0.02\n",
      "Epoch: 137/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 137/200 | Batch 100/110 | Loss: 0.00\n",
      "Epoch: 138/200 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 138/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 138/200 | Batch 040/110 | Loss: 0.03\n",
      "Epoch: 138/200 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 138/200 | Batch 080/110 | Loss: 0.00\n",
      "Epoch: 138/200 | Batch 100/110 | Loss: 0.02\n",
      "Epoch: 139/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 139/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 139/200 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 139/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 139/200 | Batch 080/110 | Loss: 0.12\n",
      "Epoch: 139/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 140/200 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 140/200 | Batch 020/110 | Loss: 0.03\n",
      "Epoch: 140/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 140/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 140/200 | Batch 080/110 | Loss: 0.10\n",
      "Epoch: 140/200 | Batch 100/110 | Loss: 0.13\n",
      "Epoch: 141/200 | Batch 000/110 | Loss: 0.04\n",
      "Epoch: 141/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 141/200 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 141/200 | Batch 060/110 | Loss: 0.03\n",
      "Epoch: 141/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 141/200 | Batch 100/110 | Loss: 0.06\n",
      "Epoch: 142/200 | Batch 000/110 | Loss: 0.10\n",
      "Epoch: 142/200 | Batch 020/110 | Loss: 0.04\n",
      "Epoch: 142/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 142/200 | Batch 060/110 | Loss: 0.06\n",
      "Epoch: 142/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 142/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 143/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 143/200 | Batch 020/110 | Loss: 0.08\n",
      "Epoch: 143/200 | Batch 040/110 | Loss: 0.06\n",
      "Epoch: 143/200 | Batch 060/110 | Loss: 0.02\n",
      "Epoch: 143/200 | Batch 080/110 | Loss: 0.12\n",
      "Epoch: 143/200 | Batch 100/110 | Loss: 0.03\n",
      "Epoch: 144/200 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 144/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 144/200 | Batch 040/110 | Loss: 0.12\n",
      "Epoch: 144/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 144/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 144/200 | Batch 100/110 | Loss: 0.00\n",
      "Epoch: 145/200 | Batch 000/110 | Loss: 0.04\n",
      "Epoch: 145/200 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 145/200 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 145/200 | Batch 060/110 | Loss: 0.03\n",
      "Epoch: 145/200 | Batch 080/110 | Loss: 0.00\n",
      "Epoch: 145/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 146/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 146/200 | Batch 020/110 | Loss: 0.08\n",
      "Epoch: 146/200 | Batch 040/110 | Loss: 0.18\n",
      "Epoch: 146/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 146/200 | Batch 080/110 | Loss: 0.11\n",
      "Epoch: 146/200 | Batch 100/110 | Loss: 0.03\n",
      "Epoch: 147/200 | Batch 000/110 | Loss: 0.07\n",
      "Epoch: 147/200 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 147/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 147/200 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 147/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 147/200 | Batch 100/110 | Loss: 0.00\n",
      "Epoch: 148/200 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 148/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 148/200 | Batch 040/110 | Loss: 0.02\n",
      "Epoch: 148/200 | Batch 060/110 | Loss: 0.11\n",
      "Epoch: 148/200 | Batch 080/110 | Loss: 0.03\n",
      "Epoch: 148/200 | Batch 100/110 | Loss: 0.00\n",
      "Epoch: 149/200 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 149/200 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 149/200 | Batch 040/110 | Loss: 0.02\n",
      "Epoch: 149/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 149/200 | Batch 080/110 | Loss: 0.03\n",
      "Epoch: 149/200 | Batch 100/110 | Loss: 0.10\n",
      "Epoch: 150/200 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 150/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 150/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 150/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 150/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 150/200 | Batch 100/110 | Loss: 0.04\n",
      "Epoch: 151/200 | Batch 000/110 | Loss: 0.12\n",
      "Epoch: 151/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 151/200 | Batch 040/110 | Loss: 0.04\n",
      "Epoch: 151/200 | Batch 060/110 | Loss: 0.02\n",
      "Epoch: 151/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 151/200 | Batch 100/110 | Loss: 0.11\n",
      "Epoch: 152/200 | Batch 000/110 | Loss: 0.10\n",
      "Epoch: 152/200 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 152/200 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 152/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 152/200 | Batch 080/110 | Loss: 0.03\n",
      "Epoch: 152/200 | Batch 100/110 | Loss: 0.05\n",
      "Epoch: 153/200 | Batch 000/110 | Loss: 0.04\n",
      "Epoch: 153/200 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 153/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 153/200 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 153/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 153/200 | Batch 100/110 | Loss: 0.02\n",
      "Epoch: 154/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 154/200 | Batch 020/110 | Loss: 0.15\n",
      "Epoch: 154/200 | Batch 040/110 | Loss: 0.13\n",
      "Epoch: 154/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 154/200 | Batch 080/110 | Loss: 0.00\n",
      "Epoch: 154/200 | Batch 100/110 | Loss: 0.11\n",
      "Epoch: 155/200 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 155/200 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 155/200 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 155/200 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 155/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 155/200 | Batch 100/110 | Loss: 0.06\n",
      "Epoch: 156/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 156/200 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 156/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 156/200 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 156/200 | Batch 080/110 | Loss: 0.00\n",
      "Epoch: 156/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 157/200 | Batch 000/110 | Loss: 0.12\n",
      "Epoch: 157/200 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 157/200 | Batch 040/110 | Loss: 0.02\n",
      "Epoch: 157/200 | Batch 060/110 | Loss: 0.02\n",
      "Epoch: 157/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 157/200 | Batch 100/110 | Loss: 0.02\n",
      "Epoch: 158/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 158/200 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 158/200 | Batch 040/110 | Loss: 0.05\n",
      "Epoch: 158/200 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 158/200 | Batch 080/110 | Loss: 0.12\n",
      "Epoch: 158/200 | Batch 100/110 | Loss: 0.02\n",
      "Epoch: 159/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 159/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 159/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 159/200 | Batch 060/110 | Loss: 0.04\n",
      "Epoch: 159/200 | Batch 080/110 | Loss: 0.03\n",
      "Epoch: 159/200 | Batch 100/110 | Loss: 0.04\n",
      "Epoch: 160/200 | Batch 000/110 | Loss: 0.04\n",
      "Epoch: 160/200 | Batch 020/110 | Loss: 0.07\n",
      "Epoch: 160/200 | Batch 040/110 | Loss: 0.04\n",
      "Epoch: 160/200 | Batch 060/110 | Loss: 0.09\n",
      "Epoch: 160/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 160/200 | Batch 100/110 | Loss: 0.03\n",
      "Epoch: 161/200 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 161/200 | Batch 020/110 | Loss: 0.04\n",
      "Epoch: 161/200 | Batch 040/110 | Loss: 0.09\n",
      "Epoch: 161/200 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 161/200 | Batch 080/110 | Loss: 0.00\n",
      "Epoch: 161/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 162/200 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 162/200 | Batch 020/110 | Loss: 0.06\n",
      "Epoch: 162/200 | Batch 040/110 | Loss: 0.02\n",
      "Epoch: 162/200 | Batch 060/110 | Loss: 0.06\n",
      "Epoch: 162/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 162/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 163/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 163/200 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 163/200 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 163/200 | Batch 060/110 | Loss: 0.02\n",
      "Epoch: 163/200 | Batch 080/110 | Loss: 0.03\n",
      "Epoch: 163/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 164/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 164/200 | Batch 020/110 | Loss: 0.03\n",
      "Epoch: 164/200 | Batch 040/110 | Loss: 0.02\n",
      "Epoch: 164/200 | Batch 060/110 | Loss: 0.04\n",
      "Epoch: 164/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 164/200 | Batch 100/110 | Loss: 0.16\n",
      "Epoch: 165/200 | Batch 000/110 | Loss: 0.11\n",
      "Epoch: 165/200 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 165/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 165/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 165/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 165/200 | Batch 100/110 | Loss: 0.13\n",
      "Epoch: 166/200 | Batch 000/110 | Loss: 0.13\n",
      "Epoch: 166/200 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 166/200 | Batch 040/110 | Loss: 0.03\n",
      "Epoch: 166/200 | Batch 060/110 | Loss: 0.04\n",
      "Epoch: 166/200 | Batch 080/110 | Loss: 0.04\n",
      "Epoch: 166/200 | Batch 100/110 | Loss: 0.02\n",
      "Epoch: 167/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 167/200 | Batch 020/110 | Loss: 0.11\n",
      "Epoch: 167/200 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 167/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 167/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 167/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 168/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 168/200 | Batch 020/110 | Loss: 0.03\n",
      "Epoch: 168/200 | Batch 040/110 | Loss: 0.03\n",
      "Epoch: 168/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 168/200 | Batch 080/110 | Loss: 0.10\n",
      "Epoch: 168/200 | Batch 100/110 | Loss: 0.09\n",
      "Epoch: 169/200 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 169/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 169/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 169/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 169/200 | Batch 080/110 | Loss: 0.00\n",
      "Epoch: 169/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 170/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 170/200 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 170/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 170/200 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 170/200 | Batch 080/110 | Loss: 0.07\n",
      "Epoch: 170/200 | Batch 100/110 | Loss: 0.09\n",
      "Epoch: 171/200 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 171/200 | Batch 020/110 | Loss: 0.08\n",
      "Epoch: 171/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 171/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 171/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 171/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 172/200 | Batch 000/110 | Loss: 0.13\n",
      "Epoch: 172/200 | Batch 020/110 | Loss: 0.21\n",
      "Epoch: 172/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 172/200 | Batch 060/110 | Loss: 0.02\n",
      "Epoch: 172/200 | Batch 080/110 | Loss: 0.04\n",
      "Epoch: 172/200 | Batch 100/110 | Loss: 0.05\n",
      "Epoch: 173/200 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 173/200 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 173/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 173/200 | Batch 060/110 | Loss: 0.02\n",
      "Epoch: 173/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 173/200 | Batch 100/110 | Loss: 0.00\n",
      "Epoch: 174/200 | Batch 000/110 | Loss: 0.04\n",
      "Epoch: 174/200 | Batch 020/110 | Loss: 0.13\n",
      "Epoch: 174/200 | Batch 040/110 | Loss: 0.05\n",
      "Epoch: 174/200 | Batch 060/110 | Loss: 0.05\n",
      "Epoch: 174/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 174/200 | Batch 100/110 | Loss: 0.00\n",
      "Epoch: 175/200 | Batch 000/110 | Loss: 0.08\n",
      "Epoch: 175/200 | Batch 020/110 | Loss: 0.05\n",
      "Epoch: 175/200 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 175/200 | Batch 060/110 | Loss: 0.02\n",
      "Epoch: 175/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 175/200 | Batch 100/110 | Loss: 0.15\n",
      "Epoch: 176/200 | Batch 000/110 | Loss: 0.04\n",
      "Epoch: 176/200 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 176/200 | Batch 040/110 | Loss: 0.13\n",
      "Epoch: 176/200 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 176/200 | Batch 080/110 | Loss: 0.10\n",
      "Epoch: 176/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 177/200 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 177/200 | Batch 020/110 | Loss: 0.04\n",
      "Epoch: 177/200 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 177/200 | Batch 060/110 | Loss: 0.02\n",
      "Epoch: 177/200 | Batch 080/110 | Loss: 0.04\n",
      "Epoch: 177/200 | Batch 100/110 | Loss: 0.00\n",
      "Epoch: 178/200 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 178/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 178/200 | Batch 040/110 | Loss: 0.05\n",
      "Epoch: 178/200 | Batch 060/110 | Loss: 0.15\n",
      "Epoch: 178/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 178/200 | Batch 100/110 | Loss: 0.00\n",
      "Epoch: 179/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 179/200 | Batch 020/110 | Loss: 0.13\n",
      "Epoch: 179/200 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 179/200 | Batch 060/110 | Loss: 0.03\n",
      "Epoch: 179/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 179/200 | Batch 100/110 | Loss: 0.04\n",
      "Epoch: 180/200 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 180/200 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 180/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 180/200 | Batch 060/110 | Loss: 0.12\n",
      "Epoch: 180/200 | Batch 080/110 | Loss: 0.03\n",
      "Epoch: 180/200 | Batch 100/110 | Loss: 0.00\n",
      "Epoch: 181/200 | Batch 000/110 | Loss: 0.10\n",
      "Epoch: 181/200 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 181/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 181/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 181/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 181/200 | Batch 100/110 | Loss: 0.03\n",
      "Epoch: 182/200 | Batch 000/110 | Loss: 0.04\n",
      "Epoch: 182/200 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 182/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 182/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 182/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 182/200 | Batch 100/110 | Loss: 0.02\n",
      "Epoch: 183/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 183/200 | Batch 020/110 | Loss: 0.11\n",
      "Epoch: 183/200 | Batch 040/110 | Loss: 0.02\n",
      "Epoch: 183/200 | Batch 060/110 | Loss: 0.03\n",
      "Epoch: 183/200 | Batch 080/110 | Loss: 0.00\n",
      "Epoch: 183/200 | Batch 100/110 | Loss: 0.00\n",
      "Epoch: 184/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 184/200 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 184/200 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 184/200 | Batch 060/110 | Loss: 0.03\n",
      "Epoch: 184/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 184/200 | Batch 100/110 | Loss: 0.00\n",
      "Epoch: 185/200 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 185/200 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 185/200 | Batch 040/110 | Loss: 0.03\n",
      "Epoch: 185/200 | Batch 060/110 | Loss: 0.10\n",
      "Epoch: 185/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 185/200 | Batch 100/110 | Loss: 0.21\n",
      "Epoch: 186/200 | Batch 000/110 | Loss: 0.06\n",
      "Epoch: 186/200 | Batch 020/110 | Loss: 0.03\n",
      "Epoch: 186/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 186/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 186/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 186/200 | Batch 100/110 | Loss: 0.04\n",
      "Epoch: 187/200 | Batch 000/110 | Loss: 0.07\n",
      "Epoch: 187/200 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 187/200 | Batch 040/110 | Loss: 0.15\n",
      "Epoch: 187/200 | Batch 060/110 | Loss: 0.03\n",
      "Epoch: 187/200 | Batch 080/110 | Loss: 0.00\n",
      "Epoch: 187/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 188/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 188/200 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 188/200 | Batch 040/110 | Loss: 0.00\n",
      "Epoch: 188/200 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 188/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 188/200 | Batch 100/110 | Loss: 0.02\n",
      "Epoch: 189/200 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 189/200 | Batch 020/110 | Loss: 0.04\n",
      "Epoch: 189/200 | Batch 040/110 | Loss: 0.02\n",
      "Epoch: 189/200 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 189/200 | Batch 080/110 | Loss: 0.12\n",
      "Epoch: 189/200 | Batch 100/110 | Loss: 0.04\n",
      "Epoch: 190/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 190/200 | Batch 020/110 | Loss: 0.13\n",
      "Epoch: 190/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 190/200 | Batch 060/110 | Loss: 0.12\n",
      "Epoch: 190/200 | Batch 080/110 | Loss: 0.13\n",
      "Epoch: 190/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 191/200 | Batch 000/110 | Loss: 0.06\n",
      "Epoch: 191/200 | Batch 020/110 | Loss: 0.14\n",
      "Epoch: 191/200 | Batch 040/110 | Loss: 0.02\n",
      "Epoch: 191/200 | Batch 060/110 | Loss: 0.22\n",
      "Epoch: 191/200 | Batch 080/110 | Loss: 0.02\n",
      "Epoch: 191/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 192/200 | Batch 000/110 | Loss: 0.02\n",
      "Epoch: 192/200 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 192/200 | Batch 040/110 | Loss: 0.07\n",
      "Epoch: 192/200 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 192/200 | Batch 080/110 | Loss: 0.10\n",
      "Epoch: 192/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 193/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 193/200 | Batch 020/110 | Loss: 0.04\n",
      "Epoch: 193/200 | Batch 040/110 | Loss: 0.04\n",
      "Epoch: 193/200 | Batch 060/110 | Loss: 0.02\n",
      "Epoch: 193/200 | Batch 080/110 | Loss: 0.03\n",
      "Epoch: 193/200 | Batch 100/110 | Loss: 0.14\n",
      "Epoch: 194/200 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 194/200 | Batch 020/110 | Loss: 0.04\n",
      "Epoch: 194/200 | Batch 040/110 | Loss: 0.05\n",
      "Epoch: 194/200 | Batch 060/110 | Loss: 0.04\n",
      "Epoch: 194/200 | Batch 080/110 | Loss: 0.00\n",
      "Epoch: 194/200 | Batch 100/110 | Loss: 0.10\n",
      "Epoch: 195/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 195/200 | Batch 020/110 | Loss: 0.02\n",
      "Epoch: 195/200 | Batch 040/110 | Loss: 0.02\n",
      "Epoch: 195/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 195/200 | Batch 080/110 | Loss: 0.11\n",
      "Epoch: 195/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 196/200 | Batch 000/110 | Loss: 0.01\n",
      "Epoch: 196/200 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 196/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 196/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 196/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 196/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 197/200 | Batch 000/110 | Loss: 0.00\n",
      "Epoch: 197/200 | Batch 020/110 | Loss: 0.01\n",
      "Epoch: 197/200 | Batch 040/110 | Loss: 0.01\n",
      "Epoch: 197/200 | Batch 060/110 | Loss: 0.00\n",
      "Epoch: 197/200 | Batch 080/110 | Loss: 0.00\n",
      "Epoch: 197/200 | Batch 100/110 | Loss: 0.05\n",
      "Epoch: 198/200 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 198/200 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 198/200 | Batch 040/110 | Loss: 0.06\n",
      "Epoch: 198/200 | Batch 060/110 | Loss: 0.03\n",
      "Epoch: 198/200 | Batch 080/110 | Loss: 0.01\n",
      "Epoch: 198/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 199/200 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 199/200 | Batch 020/110 | Loss: 0.00\n",
      "Epoch: 199/200 | Batch 040/110 | Loss: 0.03\n",
      "Epoch: 199/200 | Batch 060/110 | Loss: 0.06\n",
      "Epoch: 199/200 | Batch 080/110 | Loss: 0.00\n",
      "Epoch: 199/200 | Batch 100/110 | Loss: 0.01\n",
      "Epoch: 200/200 | Batch 000/110 | Loss: 0.03\n",
      "Epoch: 200/200 | Batch 020/110 | Loss: 0.15\n",
      "Epoch: 200/200 | Batch 040/110 | Loss: 0.05\n",
      "Epoch: 200/200 | Batch 060/110 | Loss: 0.01\n",
      "Epoch: 200/200 | Batch 080/110 | Loss: 0.00\n",
      "Epoch: 200/200 | Batch 100/110 | Loss: 0.03\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "model = LogisticRegression(num_features=4)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 200\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model = model.train()\n",
    "    for batch_idx, (features, class_labels) in enumerate(train_loader):\n",
    "\n",
    "        probas = model(features)\n",
    "       \n",
    "        loss = F.binary_cross_entropy(probas, class_labels.view(probas.shape))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 20: # log every 20th batch\n",
    "            print(f'Epoch: {epoch+1:03d}/{num_epochs:03d}'\n",
    "                   f' | Batch {batch_idx:03d}/{len(train_loader):03d}'\n",
    "                   f' | Loss: {loss:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, dataloader):\n",
    "\n",
    "    model = model.eval()\n",
    "    \n",
    "    correct = 0.0\n",
    "    total_examples = 0\n",
    "    \n",
    "    for idx, (features, class_labels) in enumerate(dataloader):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            probas = model(features)\n",
    "        \n",
    "        pred = torch.where(probas > 0.5, 1, 0)\n",
    "        lab = class_labels.view(pred.shape).to(pred.dtype)\n",
    "\n",
    "        compare = lab == pred\n",
    "        correct += torch.sum(compare)\n",
    "        total_examples += len(compare)\n",
    "\n",
    "    return correct / total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.72%\n"
     ]
    }
   ],
   "source": [
    "train_acc = compute_accuracy(model, train_loader)\n",
    "print(f\"Accuracy: {train_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.27%\n"
     ]
    }
   ],
   "source": [
    "val_acc = compute_accuracy(model, val_loader)\n",
    "print(f\"Accuracy: {val_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shah",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
